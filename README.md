# ollama_PDF_CHAT
PDF_Chat w/Ollama LLMs

Inspired by https://github.com/alejandro-ao/ask-multiple-pdfs

This is a basic streamlit powered personal pdfchat webapp.
It is self hosted with ollama.

Install ollama
Pull the necessary models.
This uses llama2-uncensored for the chat, should work with all ollama models

Clone Repo, cd to clone path

Setup your eviroment & install modules: "pip install -r requirements.txt"

Run "ollama serve"

Run "streamlit run app.py"

![Screenshot from 2023-11-14 21-43-58](https://github.com/StuckNSpace/ollama_PDF_CHAT/assets/34696551/fb2b16ca-c738-4e71-bc24-2d3c1f3cbb4f)
